{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import prepare_simulation, prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ra = 77.358 # degrees\n",
    "source_dec = 5.693 # degrees\n",
    "\n",
    "ra_bins = np.radians(np.linspace(72, 82, 21))\n",
    "dec_bins = np.radians(np.linspace(0, 10, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = prepare_simulation(source_ra, source_dec, # degrees\n",
    "                           window = 5, # degrees\n",
    "                           E0 = 1000, # GeV,\n",
    "                           gamma = 2,\n",
    "                           time_mean = 57000,\n",
    "                           time_sigma = 100,\n",
    "                           simfile = \"/data/mjlarson/datasets/ps_tracks/version-003-p02/IC86_2012_MC.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And grab the data\n",
    "data = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make your histograms. \n",
    "\n",
    "We'll use ra and dec binning here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to use np.histogram2d instead of pyplot.hist2d\n",
    "# since we don't need to look at the plots...\n",
    "data_hist, _, _ = np.histogram2d(data['ra'], data['dec'],\n",
    "                                 bins = (ra_bins, dec_bins))\n",
    "signal_hist, _, _ = np.histogram2d(sim['ra'], sim['dec'],\n",
    "                                   bins = (ra_bins, dec_bins),\n",
    "                                   weights=sim['probability_weight'])\n",
    "\n",
    "bg_hist = np.histogram(data['dec'], bins=dec_bins)[0] \n",
    "bg_hist = bg_hist/bg_hist.sum() / (len(ra_bins)-1)\n",
    "bg_hist = bg_hist[None, :]*np.ones_like(data_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do a simple fit\n",
    "\n",
    "We believe our data histogram $k$ is some combination of the signal histogram $S$ and background histogram $B$ so that\n",
    "\n",
    ">   $k = (\\hat{N}_b * B) + (\\hat{N}_s * S)$\n",
    "   \n",
    "with $\\hat{N}_b$ representing the number of background events and $\\hat{N}_s$ the true number of signal events. We don't actually know the right values of $\\hat{N}_b$ and $\\hat{N}_s$ yet, though. To find them, let's do a simple $chi^2$ fit with two free parameters $N_b$ and $N_s$. The $chi^2$ fit is defined in terms of the expectation $\\lambda(N_b, N_s)$ as\n",
    "\n",
    "> $\\chi^2(N_b, N_s) = \\left(\\lambda(N_b, N_s) - k\\right)^2$  /  $\\lambda(N_b, N_s)$\n",
    "\n",
    "Let's look at the implementation of the expectation and $\\chi^2$ below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(N_b, bg_hist,\n",
    "                N_s, signal_hist):\n",
    "    return N_b*bg_hist + N_s*signal_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(data_hist, \n",
    "         N_b, bg_hist, \n",
    "         N_s, signal_hist):\n",
    "    exp_hist = expectation(N_b, bg_hist, \n",
    "                           N_s, signal_hist)\n",
    "    \n",
    "    with np.errstate(divide='ignore'):\n",
    "        per_bin_chi2 = ((data_hist-exp_hist)**2 / exp_hist)\n",
    "        per_bin_chi2[~np.isfinite(per_bin_chi2)] = 0\n",
    "    return per_bin_chi2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we do the fit using scipy\n",
    "fit_func = lambda params: chi2(data_hist=data_hist, \n",
    "                               N_b=params[0], bg_hist=bg_hist,\n",
    "                               N_s=params[1], signal_hist=signal_hist)\n",
    "\n",
    "results = minimize(fit_func, \n",
    "                   x0 = [data_hist.sum(), 0.0],\n",
    "                   bounds = [[0.9*data_hist.sum(), 1.1*data_hist.sum()], \n",
    "                              [0, 1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at the output numbers\n",
    "\n",
    "We've fit a value now: N_s. Let's take a look at our best fit values out of the `scipy.optimize.minimize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results)\n",
    "data_bestfit_chi2 = results.fun\n",
    "data_bestfit_N_s= results.x[1]\n",
    "\n",
    "print(f\"Found a best-fit of {data_bestfit_N_s} signal events\")\n",
    "print(f\"Final chi2 value: {data_bestfit_chi2} with {len(data_hist.ravel())} degrees of freedom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is this good?\n",
    "\n",
    "Did we find signal events?  chi2/ndof < 1! But is this good? Is this \n",
    "significant? We actually don't know: it's entirely possible that our fit can \n",
    "return signal events just by chance. To really be able to tell, we need to be \n",
    "able to see how often our fit sees a \"signal\" like this from background alone.\n",
    "\n",
    "We do this by producing simulated data (randomizing RA) with N_b=1 and N_s=0. \n",
    "We call this simulated a data a \"background trial\" or, more generically, simply \n",
    "a \"trial\"\n",
    "\n",
    ">  bg_trial_hist = expectation(N_s=0) = ((N-0) * bg_hist) + (0*signal_hist)\n",
    "\n",
    ">  bg_trial_hist = bg_hist\n",
    "\n",
    "At this point, we have two options: we can either use `np.random.poisson` on \n",
    "`bg_hist` to get a random sample of events based on the background or we can \n",
    "randomize the RA values directly from the data. Let's do the former, since it's\n",
    "a bit faster.\n",
    "\n",
    "Let's write a simple function to pick random RA values and return a new \"data_hist\" \n",
    "and redo our fit again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bg_trial_hist(N=data_hist.sum(), bg_hist=bg_hist):\n",
    "    return np.random.poisson(N*bg_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_hist = make_bg_trial_hist(data_hist.sum(),\n",
    "                                bg_hist)\n",
    "\n",
    "fit_func = lambda params: chi2(data_hist=trial_hist, \n",
    "                               N_b=params[0], bg_hist=bg_hist,\n",
    "                               N_s=params[1], signal_hist=signal_hist)\n",
    "\n",
    "trial_results = minimize(fit_func, \n",
    "                         x0 = [data_hist.sum(), 0.0],\n",
    "                         bounds = [[0.9*data_hist.sum(), 1.1*data_hist.sum()], \n",
    "                                   [0, 1000]])  \n",
    "\n",
    "#print(results)\n",
    "trial_bestfit_chi2 = trial_results.fun\n",
    "trial_bestfit_N_s = trial_results.x[1]\n",
    "\n",
    "print(f\"Found a best-fit of {trial_bestfit_N_s} signal events\")\n",
    "print(f\"Final chi2 value: {trial_bestfit_chi2} with {len(trial_hist.ravel())} degrees of freedom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does this help?\n",
    "\n",
    "We now have another fit. We know this one doesn't include any signal, so it's\n",
    "just testing what happens if there were only background. It looks like the fit\n",
    "can return N_s > 0, even when there's background. We still don't know how often\n",
    "that happens, though. To figure that out, we need to build a \"test statistic\"\n",
    "distribution.\n",
    "\n",
    "A \"test statistic\" (\"TS\") is normally something that you can use to distinguish \n",
    "between signal from background. For the moment, let's use the value of N_s as our \n",
    "test statistic and write something to build a distribution of TS values from background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_values(data, \n",
    "                  bg_hist,\n",
    "                  signal_hist,\n",
    "                  bins,\n",
    "                  n_trials):\n",
    "    ts_values = []\n",
    "    for i in tqdm(range(n_trials)):\n",
    "        trial_hist = make_bg_trial_hist(N=data_hist.sum(), bg_hist=bg_hist)\n",
    "        fit_func = lambda params: chi2(data_hist=trial_hist, \n",
    "                                       N_b=params[0], bg_hist=bg_hist,\n",
    "                                       N_s=params[1], signal_hist=signal_hist)\n",
    "        trial_results = minimize(fit_func, \n",
    "                                 x0 = [trial_hist.sum(), 0.0],\n",
    "                                 bounds = [[0.9*trial_hist.sum(), 1.1*trial_hist.sum()], \n",
    "                                           [0, 1000]])  \n",
    "        ts_values.append(trial_results.x[1])\n",
    "        \n",
    "    return np.array(ts_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_trial_ns_values = get_ts_values(data = data, \n",
    "                                   bg_hist = bg_hist,\n",
    "                                   signal_hist = signal_hist,\n",
    "                                   bins = (ra_bins, dec_bins),\n",
    "                                   n_trials = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out how rare our best-fit value is in the background distribution!\n",
    "# This is where we find out how significant our result is!\n",
    "frac_trials_above_data = (bg_trial_ns_values >= data_bestfit_N_s).sum() / len(bg_trial_ns_values)\n",
    "print(f\"Our data fit has a pvalue = {frac_trials_above_data:4.3e}\")\n",
    "print(f\"Alternatively, we see {len(bg_trial_ns_values)*frac_trials_above_data}/{len(bg_trial_ns_values)}\"\n",
    "      \" background trials more significant than the data.\")\n",
    "\n",
    "# And plot them along with our original data TS value.\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.hist(bg_trial_ns_values, \n",
    "            bins = 50,\n",
    "            histtype='stepfilled',\n",
    "            linewidth=3,\n",
    "            label = 'BG Trials')\n",
    "\n",
    "# And draw our data TS value.\n",
    "ax.axvline(data_bestfit_N_s,\n",
    "           color='k',\n",
    "           label=\"Bestfit from Data\"\n",
    "          )\n",
    "\n",
    "# Make it look nicer.\n",
    "ax.legend(loc='upper center', ncol=2, fontsize=12, framealpha=1)\n",
    "ax.grid(alpha=0.1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r\"N$_s$\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of trials\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
